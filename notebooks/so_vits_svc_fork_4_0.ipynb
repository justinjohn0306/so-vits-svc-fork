{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Maintained by [justinjohn03](https://github.com/justinjohn0306)**\n",
        "___\n",
        "Special thanks to: [MLo7](https://github.com/MLo7Ghinsan)"
      ],
      "metadata": {
        "id": "uzImPbSTm5dj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYGUwfNjUjWU"
      },
      "source": [
        "## Before training\n",
        "\n",
        "This program saves the last 3 generations of models to Google Drive. Since 1 generation of models is >1GB, you should have at least 3GB of free space in Google Drive. If you do not have such free space, it is recommended to create another Google Account.\n",
        "\n",
        "Training requires >10GB VRAM. (T4 should be enough) Inference does not require such a lot of VRAM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPuJSiUFUjWc"
      },
      "source": [
        "## **Installation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DJWqGb5BUjWd"
      },
      "outputs": [],
      "source": [
        "#@title Check GPU\n",
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install so-vits-svc-fork\n",
        "\n",
        "#@markdown # Install so-vits-svc-fork, mount google drive and select which directories to sync with google drive\n",
        "\n",
        "#@markdown\n",
        "\n",
        "%cd /content\n",
        "!mkdir -p \"dataset_raw\"\n",
        "!mkdir -p \"logs/44k\"\n",
        "!mkdir -p \"configs\"\n",
        "!mkdir -p \"raw\"\n",
        "\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "from google.colab import drive\n",
        "from IPython.display import Audio, display, HTML\n",
        "\n",
        "if not os.path.exists(\"/content/play_sound\"):\n",
        "    os.makedirs(\"/content/play_sound\")\n",
        "%cd /content/play_sound\n",
        "!wget -O setup_complete.wav https://github.com/MLo7Ghinsan/MLo7_Diff-SVC_models/releases/download/audio/setup_complete.wav\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "clear_output()\n",
        "\n",
        "%cd /content\n",
        "\n",
        "!python -m pip install -U pip setuptools wheel\n",
        "%pip install -U ipython \n",
        "#@markdown Branch (for development)\n",
        "BRANCH = \"none\" #@param {\"type\": \"string\"}\n",
        "if BRANCH == \"none\":\n",
        "    %pip install -U so-vits-svc-fork\n",
        "else:\n",
        "    %pip install -U git+https://github.com/34j/so-vits-svc-fork.git@{BRANCH}\n",
        "\n",
        "clear_output()\n",
        "\n",
        "#@markdown Directory to store **necessary files**, dont miss the slash at the endðŸ‘‡.\n",
        "sovits_data_dir = \"/content/drive/MyDrive/so-vits-svc-fork/\"  #@param {type:\"string\"}\n",
        "#@markdown By default it will create a `so-vits-svc-fork/` folder in your google drive.\n",
        "RAW_DIR = sovits_data_dir + \"raw/\"\n",
        "RESULTS_DIR = sovits_data_dir + \"results/\"\n",
        "FILELISTS_DIR = sovits_data_dir + \"filelists/\"\n",
        "CONFIGS_DIR = sovits_data_dir + \"configs/\"\n",
        "LOGS_DIR = sovits_data_dir + \"logs/44k/\"\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown ### These folders will be synced with your google drive\n",
        "\n",
        "#@markdownã€€### **Strongly recommend to check all.**\n",
        "\n",
        "#@markdown Sync **input audios** and **output audios**\n",
        "sync_raw_and_results = True  #@param {type:\"boolean\"}\n",
        "if sync_raw_and_results:\n",
        "  !mkdir -p {RAW_DIR}\n",
        "  !mkdir -p {RESULTS_DIR}\n",
        "  !rm -rf /content/raw\n",
        "  !rm -rf /content/results\n",
        "  !ln -s {RAW_DIR} /content/raw\n",
        "  !ln -s {RESULTS_DIR} /content/results\n",
        "\n",
        "#@markdown Sync **config** and **models**\n",
        "sync_configs_and_logs = True  #@param {type:\"boolean\"}\n",
        "if sync_configs_and_logs:\n",
        "  !mkdir -p {FILELISTS_DIR}\n",
        "  !mkdir -p {CONFIGS_DIR}\n",
        "  !mkdir -p {LOGS_DIR}\n",
        "  !rm -rf /content/filelists\n",
        "  !rm -rf /content/configs\n",
        "  !rm -rf /content/logs/44k\n",
        "  !ln -s {FILELISTS_DIR} /content/filelists\n",
        "  !ln -s {CONFIGS_DIR} /content/configs\n",
        "  !ln -s {LOGS_DIR} /content/logs/44k\n",
        "\n",
        "\n",
        "  clear_output()\n",
        "\n",
        "print(\"setup complete!\")\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "\n",
        "chika_dance = '<img src=\"https://cdn.discordapp.com/attachments/816517150175920138/1090112497446563950/icegif-2013.gif\"/>'\n",
        "display(HTML(chika_dance))\n",
        "\n",
        "with open(\"/content/play_sound/setup_complete.wav\", \"rb\") as f:\n",
        "    setup_complete_sound = f.read()\n",
        "Audio(data=setup_complete_sound, autoplay=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "N-Y-RsoaHMG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIB0jbc-UjWh"
      },
      "source": [
        "## **Preperation**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure the file structure in your zip file looks like this for Multispeakers:\n",
        "\n",
        "```\n",
        "YourZIPforMultipleSpeakers.zip\n",
        "â”œâ”€â”€â”€speaker0\n",
        "â”‚   â”œâ”€â”€â”€xxx1-xxx1.wav\n",
        "â”‚   â”œâ”€â”€â”€...\n",
        "â”‚   â””â”€â”€â”€Lxx-0xx8.wav\n",
        "â””â”€â”€â”€speaker1\n",
        "    â”œâ”€â”€â”€xx2-0xxx2.wav\n",
        "    â”œâ”€â”€â”€...\n",
        "    â””â”€â”€â”€xxx7-xxx007.wav\n",
        "```"
      ],
      "metadata": {
        "id": "WVFSgQUsL_Cq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "from tqdm import tqdm\n",
        "#@title #2.0 | Extract data | Resume training from checkpoint\n",
        "%cd /content\n",
        "clear_output()\n",
        "#@markdown ___\n",
        "#@markdown ###Train from scratch section\n",
        "#@markdown +=========================+\n",
        "#@markdown ####Directory of the zip file that contain all of your recordings that you want to use to train a model\n",
        "train_from_scratch = False #@param {type:\"boolean\"}\n",
        "raw_data_zip_path = \"/content/drive/MyDrive/so-vits-svc-fork/test.zip\"  #@param {type:\"string\"}\n",
        "model_name = \"test\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ___\n",
        "#@markdown ###Resume training section\n",
        "#@markdown +=======================+\n",
        "resume_training = False #@param {type:\"boolean\"}\n",
        "#@markdown Directory of the zip file that THIS NOTEBOOK saved, or any zip that is in the same structure\n",
        "preprocessed_data_zip_path = \"/content/drive/MyDrive/so-vits-svc-fork/dataset.zip\" #@param {type:\"string\"}\n",
        "#@markdown ___\n",
        "\n",
        "class DeezNutz(Exception):\n",
        "    pass\n",
        "if train_from_scratch and resume_training:\n",
        "# sussy\n",
        "# amogus\n",
        "    raise DeezNutz(\"You can't select both of the options\")\n",
        "# If you are seeing this that means you select both options, you can't do that!\n",
        "else:\n",
        "  pass\n",
        "\n",
        "if not train_from_scratch and not resume_training:\n",
        "# sussy\n",
        "# amogus\n",
        "    raise DeezNutz(\"You need to select an option to proceed\")\n",
        "# If you are seeing this that means you didn't select anything!\n",
        "else:\n",
        "  pass\n",
        "\n",
        "if train_from_scratch:\n",
        "  if not os.path.exists(f\"/content/dataset_raw/{model_name}\"):\n",
        "    os.makedirs(f\"/content/dataset_raw/{model_name}\")\n",
        "  with zipfile.ZipFile(raw_data_zip_path, \"r\") as zip_ref:\n",
        "    wav_files = [f for f in zip_ref.namelist() if f.endswith('.wav')]\n",
        "    for file in tqdm(iterable=wav_files, total=len(wav_files), desc=\"Extracting files\", unit=\"files\"):\n",
        "      zip_ref.extract(member=file, path=f\"/content/dataset_raw/{model_name}\")\n",
        "  print(\"Training option: train a model from scratch\")\n",
        "else:\n",
        "  pass\n",
        "\n",
        "if resume_training:\n",
        "  with zipfile.ZipFile(preprocessed_data_zip_path, \"r\") as zip_ref:\n",
        "    for file in tqdm(iterable=zip_ref.namelist(), total=len(zip_ref.namelist()), desc=\"Extracting files\", unit=\"files\"):\n",
        "      zip_ref.extract(member=file)\n",
        "  print(\" Training option: resume training from preprocessed data\")\n",
        "else:\n",
        "  pass\n",
        "\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "wwX_KfpxFrRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Optional) **Load your multispeaker dataset from drive**"
      ],
      "metadata": {
        "id": "DM8k2cPnK0ia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Get raw dataset from google drive\n",
        "\n",
        "#@markdown # Get raw dataset from google drive\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown Directory where **your zip file** located in, dont miss the slash at the endðŸ‘‡.\n",
        "sovits_data_dir = \"/content/drive/MyDrive/so-vits-svc-fork/\"  #@param {type:\"string\"}\n",
        "#@markdown Filename of **your zip file**, do NOT be \"dataset.zip\"\n",
        "zip_filename = \"YourDataset.zip\"  #@param {type:\"string\"}\n",
        "ZIP_PATH = sovits_data_dir + zip_filename\n",
        "\n",
        "!unzip -od /content/dataset_raw {ZIP_PATH}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "N3Vh1j5EKr5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocessing**"
      ],
      "metadata": {
        "id": "uITyvR13nlk2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eR_Xkl_wUjWk",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ## Resample audio\n",
        "!svc pre-resample"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ## Generate config and filelists\n",
        "!svc pre-config -t so-vits-svc-4.0v1-legacy"
      ],
      "metadata": {
        "cellView": "form",
        "id": "enzTA_d0nfg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ekwSB_mHUjWk"
      },
      "outputs": [],
      "source": [
        "#@markdown ## Extract F0\n",
        "\n",
        "F0_METHOD = \"dio\" #@param [\"crepe\", \"crepe-tiny\", \"parselmouth\", \"dio\", \"harvest\"]\n",
        "!svc pre-hubert -fm {F0_METHOD}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Optional**"
      ],
      "metadata": {
        "id": "bHSvtnNAJMBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Backup the preprocessed dataset to google drive\n",
        "\n",
        "#@markdown # Backup the preprocessed dataset to google drive\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown You can save the dataset and the preprocessed files to your google drive for the next training\n",
        "\n",
        "#@markdown **Directory for saving**, dont miss the slash at the endðŸ‘‡.\n",
        "sovits_data_dir = \"/content/drive/MyDrive/so-vits-svc-fork/\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown There will be a `dataset.zip` contained `dataset/` in your google drive, which is preprocessed data.\n",
        "\n",
        "!mkdir -p {sovits_data_dir}\n",
        "!zip -r dataset.zip dataset\n",
        "!cp -vr dataset.zip \"{sovits_data_dir}\"\n",
        "!rm dataset.zip"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zjXMMQfXImKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**"
      ],
      "metadata": {
        "id": "RRXt-Ai1nuVF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMHUCvYHUjWl",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ## Start training\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir drive/MyDrive/so-vits-svc-fork/logs/44k\n",
        "!svc train --model-path drive/MyDrive/so-vits-svc-fork/logs/44k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkvXkwd2UjWl"
      },
      "source": [
        "## **Training Cluster model**\n",
        "\n",
        "(Optional but still recommended) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ui3IIA_jUjWm",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ## Start training cluster model\n",
        "\n",
        "!svc train-cluster --output-path drive/MyDrive/so-vits-svc-fork/logs/44k/kmeans.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inference**\n",
        "__________"
      ],
      "metadata": {
        "id": "riqqxKxQETxw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEK6I-NMUjWm"
      },
      "source": [
        "# **Inference for Basic Users**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #2.0 Start inference\n",
        "\n",
        "#@markdown Parameters see [README.MD#inference](https://github.com/voicepaw/so-vits-svc-fork#usage)\n",
        "\n",
        "#@markdown\n",
        "\n",
        "input_wav_path = \"/content/play_sound/setup_complete.wav\"  #@param {type:\"string\"}\n",
        "wav_base_name = os.path.splitext(os.path.basename(input_wav_path))[0]\n",
        "model_path = \"/content/drive/MyDrive/so-vits-svc-fork/logs/44k/G_12000.pth\"  #@param {type:\"string\"}\n",
        "model_name = \"test\"  #@param {type:\"string\"}\n",
        "config_path = \"/content/drive/MyDrive/so-vits-svc-fork/logs/44k/config.json\"  #@param {type:\"string\"}\n",
        "f0_method = \"dio\" #@param [\"crepe\", \"crepe-tiny\", \"parselmouth\", \"dio\", \"harvest\"]\n",
        "pitch = 0 #@param {type:\"slider\", min:-36, max:36, step:1}\n",
        "\n",
        "output_path = \"/content/play_sound\" #@param {type:\"string\"}\n",
        "output_filetype = \".flac\" #@param [\".wav\", \".flac\"]\n",
        "output_audio = output_path + \"/\" + wav_base_name + \"_\" + model_name + \"_\" + f\"pitch={pitch}\" + \"_\" + f0_method + output_filetype\n",
        "#@markdown\n",
        "\n",
        "#@markdown Advanced parameters (keep default if you don't know what they do):\n",
        "\n",
        "\n",
        "!svc infer {input_wav_path} -m {model_path} -s {model_name} -c {config_path} -fm {f0_method} -t {pitch} -na -o {output_audio}\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "c9E7om7FWjYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #2.0 Display inferred audio\n",
        "\n",
        "from IPython.display import display, Audio, HTML\n",
        "import base64\n",
        "\n",
        "print(\"Input Audio\")\n",
        "display(Audio(f\"{input_wav_path}\", autoplay=False))\n",
        "audio_data = open(output_audio, \"rb\").read()\n",
        "print(\"Synthesized Audio\")\n",
        "display(Audio(audio_data, autoplay=True))\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "if os.path.exists(output_audio):\n",
        "    with open(output_audio, \"rb\") as f:\n",
        "        audio_bytes = f.read()\n",
        "    b64 = base64.b64encode(audio_bytes).decode(\"utf-8\")\n",
        "    href = f'<a href=\"data:audio/wav;base64,{b64}\" download=\"{os.path.basename(output_audio)}\" style=\"font-size: 40px;\">Download Audio</a>'\n",
        "    display(HTML(href))\n"
      ],
      "metadata": {
        "id": "DLsZztkLWzct",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inference for Advanced Users**\n",
        "\n",
        "Click this bar to unlock the cells ðŸ‘‡"
      ],
      "metadata": {
        "id": "I_NrFcVXEAI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #2.1 Start inference (For Advanced Users)\n",
        "\n",
        "#@markdown Parameters see [README.MD#inference](https://github.com/voicepaw/so-vits-svc-fork#usage)\n",
        "\n",
        "#@markdown\n",
        "\n",
        "input_wav_path = \"/content/play_sound/setup_complete.wav\"  #@param {type:\"string\"}\n",
        "wav_base_name = os.path.splitext(os.path.basename(input_wav_path))[0]\n",
        "model_path = \"/content/drive/MyDrive/so-vits-svc-fork/logs/44k/G_12000.pth\"  #@param {type:\"string\"}\n",
        "model_name = \"test\"  #@param {type:\"string\"}\n",
        "config_path = \"/content/drive/MyDrive/so-vits-svc-fork/logs/44k/config.json\"  #@param {type:\"string\"}\n",
        "cluster_model_path = \"/content/drive/MyDrive/so-vits-svc-fork/logs/44k/kmeans.pt\" #@param {type:\"string\"}\n",
        "f0_method = \"dio\" #@param [\"crepe\", \"crepe-tiny\", \"parselmouth\", \"dio\", \"harvest\"]\n",
        "pitch = 0 #@param {type:\"slider\", min:-36, max:36, step:1}\n",
        "\n",
        "output_path = \"/content/play_sound\" #@param {type:\"string\"}\n",
        "output_filetype = \".flac\" #@param [\".wav\", \".flac\"]\n",
        "output_audio = output_path + \"/\" + wav_base_name + \"_\" + model_name + \"_\" + f\"pitch={pitch}\" + \"_\" + f0_method + output_filetype\n",
        "#@markdown\n",
        "\n",
        "#@markdown Advanced parameters (keep default if you don't know what they do):\n",
        "\n",
        "threshold_db = -40 #@param {type:\"slider\", min:-60, max:0, step:5}\n",
        "cluster_ratio = 0 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "noise_scale = 0.4 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "pad_seconds = 0.5 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "chunk_seconds = 0.5 #@param {type:\"slider\", min:0, max:3, step:0.05}\n",
        "\n",
        "\n",
        "!svc infer {input_wav_path} -m {model_path} -s {model_name} -c {config_path} -fm {f0_method} -t {pitch} -db {threshold_db} -k {cluster_model_path} -r {cluster_ratio} -n {noise_scale} -p {pad_seconds} -ch {chunk_seconds} -na -o {output_audio}\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "gBsZen7bDKn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #2.1 Display inferred audio\n",
        "\n",
        "from IPython.display import display, Audio, HTML\n",
        "import base64\n",
        "\n",
        "print(\"Input Audio\")\n",
        "display(Audio(f\"{input_wav_path}\", autoplay=False))\n",
        "audio_data = open(output_audio, \"rb\").read()\n",
        "print(\"Synthesized Audio\")\n",
        "display(Audio(audio_data, autoplay=True))\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "if os.path.exists(output_audio):\n",
        "    with open(output_audio, \"rb\") as f:\n",
        "        audio_bytes = f.read()\n",
        "    b64 = base64.b64encode(audio_bytes).decode(\"utf-8\")\n",
        "    href = f'<a href=\"data:audio/wav;base64,{b64}\" download=\"{os.path.basename(output_audio)}\" style=\"font-size: 40px;\">Download Audio</a>'\n",
        "    display(HTML(href))\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ts-7UXXgDMvh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "DM8k2cPnK0ia",
        "jEK6I-NMUjWm"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
